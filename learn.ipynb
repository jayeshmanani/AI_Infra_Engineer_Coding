{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4caf0a9e-19d2-4a84-969f-b13766795fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayes\\Downloads\\CodingTask\\ai_infra_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ed1076-0b17-4e40-97a8-6a9c8e5a427a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca965d9c-22f8-4941-a57d-630a52017b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e6a3d8-d922-48dc-bfee-6fc689bd9d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductModel:\n",
    "    def __init__(self):\n",
    "        self.model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "        print(\"Quantizing model components for CPU compatibility (mocking TensorRT)...\")\n",
    "        self.model.vision_model = torch.quantization.quantize_dynamic(\n",
    "            self.model.vision_model, {torch.nn.Linear}, dtype=torch.qint8\n",
    "        )\n",
    "        self.model.text_model = torch.quantization.quantize_dynamic(\n",
    "            self.model.text_model, {torch.nn.Linear}, dtype=torch.qint8\n",
    "        )\n",
    "        self.model.visual_projection = torch.quantization.quantize_dynamic(\n",
    "            self.model.visual_projection, {torch.nn.Linear}, dtype=torch.qint8\n",
    "        )\n",
    "        self.model.text_projection = torch.quantization.quantize_dynamic(\n",
    "            self.model.text_projection, {torch.nn.Linear}, dtype=torch.qint8\n",
    "        )\n",
    "        self.model.eval()\n",
    "\n",
    "    def get_image_embeddings(self, image_path):\n",
    "        try:\n",
    "            # Open and process the image\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "            # Extract image embeddings using the vision model\n",
    "            with torch.no_grad():\n",
    "                # Use only the vision model to get image embeddings\n",
    "                vision_outputs = self.model.vision_model(pixel_values=inputs['pixel_values'])\n",
    "                image_embeds = vision_outputs.pooler_output  # Pooled output from vision transformer\n",
    "                image_embeds = self.model.visual_projection(image_embeds)  # Project to common space\n",
    "            return image_embeds.numpy()\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to get Image embeddings: {str(e)}\")\n",
    "        \n",
    "\n",
    "    def get_text_embeddings(self, text):\n",
    "        try:\n",
    "            inputs = self.processor(text=[text], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            with torch.no_grad():\n",
    "                text_outputs = self.model.text_model(\n",
    "                    input_ids=inputs['input_ids'],\n",
    "                    attention_mask=inputs['attention_mask']\n",
    "                )\n",
    "                text_embeds = text_outputs.pooler_output\n",
    "                text_embeds = self.model.text_projection(text_embeds)\n",
    "            return text_embeds.numpy()\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to get text embeddings: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e4972-32bc-468a-9c59-774ed46bb759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f9a5146-9b6b-4c21-ac2f-7e0156c6b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a612c7af-5276-4791-81a0-e0d67518aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('data/image2.jpg').convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20377f52-b6db-4cee-8db3-542882582a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=image, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9657e88-b4d2-42f7-9f20-3f76d6b632ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Use only the vision model to get image embeddings\n",
    "    vision_outputs = model.vision_model(pixel_values=inputs['pixel_values'])\n",
    "    image_embeds = vision_outputs.pooler_output  # Pooled output from vision transformer\n",
    "    image_embeds = model.visual_projection(image_embeds)  # Project to common space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "995e8a08-246b-4c70-9b1e-af4ddeb51b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = image_embeds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5621297c-46f0-4470-ac48-1d55cff03cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {'name': 'image2', 'category': 'image2', 'price': 2.0, 'filename': 'image2.jpg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77486051-e1cb-445c-96f3-269ddd92c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = metadata.get(\"id\", str(np.random.randint(10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc1df624-7ac2-497e-983f-46971d043e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7196'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "005d955c-c6df-4a71-85cf-ca397fbb6808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import chromadb\n",
    "from config import Config\n",
    "\n",
    "class Database:\n",
    "    def __init__(self):\n",
    "        # MongoDB Atlas\n",
    "        self.mongo_client = MongoClient(Config.MONGO_URI)\n",
    "        self.db = self.mongo_client[Config.DB_NAME]\n",
    "        self.products = self.db['products']\n",
    "        self.logs = self.db['logs']\n",
    "        \n",
    "        # Local ChromaDB\n",
    "        self.chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "        self.image_collection = self.chroma_client.create_collection(Config.IMAGE_COLLECTION, get_or_create=True)\n",
    "        self.text_collection = self.chroma_client.create_collection(Config.TEXT_COLLECTION, get_or_create=True)\n",
    "\n",
    "    def add_product(self, image_embedding, text_embedding, metadata, product_id):\n",
    "        try:\n",
    "            self.image_collection.add(embeddings=image_embedding.tolist(), ids=[product_id])\n",
    "            self.text_collection.add(embeddings=text_embedding.tolist(), ids=[product_id])\n",
    "            metadata[\"embedding_id\"] = product_id\n",
    "            self.products.insert_one(metadata)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logs.insert_one({\"error\": str(e)})\n",
    "            return False\n",
    "\n",
    "    def find_product(self, product_id):\n",
    "        return self.products.find_one({\"embedding_id\": product_id})\n",
    "\n",
    "    def query_vector(self, image_embedding=None, text_embedding=None):\n",
    "        if image_embedding is None and text_embedding is None:\n",
    "            raise ValueError(\"At least one embedding must be provided in Query Vector Search\")\n",
    "        \n",
    "        if image_embedding is not None and text_embedding is not None:\n",
    "            image_result = self.image_collection.query(query_embeddings=image_embedding.tolist(), n_results=1)\n",
    "            text_result = self.text_collection.query(query_embeddings=text_embedding.tolist(), n_results=1)\n",
    "            combined_distance = (image_result['distances'][0][0] + text_result['distances'][0][0]) / 2\n",
    "            return {\n",
    "                'ids': image_result['ids'],  # Assuming same order; could refine with more logic\n",
    "                'distances': [[combined_distance]]\n",
    "            }\n",
    "        elif image_embedding is not None:\n",
    "            return self.image_collection.query(query_embeddings=image_embedding.tolist(), n_results=1)\n",
    "        elif text_embedding is not None:\n",
    "            return self.text_collection.query(query_embeddings=text_embedding.tolist(), n_results=1)\n",
    "\n",
    "    def log_error(self, error):\n",
    "        self.logs.insert_one({\"error\": str(error)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcdce65c-a283-4eb2-bf69-eee3fdcd2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "746a4154-1543-406d-9288-f940d5dc014c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Database.add_product() missing 1 required positional argument: 'product_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43mem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Database.add_product() missing 1 required positional argument: 'product_id'"
     ]
    }
   ],
   "source": [
    "db.add_product(em, metadata, product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e546a90e-1120-45af-a340-d1c3ca2f2937",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'products' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mproducts\u001b[49m\u001b[38;5;241m.\u001b[39mfind_one({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: product_id})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'products' is not defined"
     ]
    }
   ],
   "source": [
    "products.find_one({\"embedding_id\": product_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50021fb5-224c-4c25-a79d-a1583257f4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.3531e-01, -2.7229e-01, -4.1955e-01,  1.4281e-01,  1.1481e-01,\n",
       "         -2.7920e-01,  1.6093e-01,  1.1949e-01,  2.9444e-01,  4.5332e-01,\n",
       "          1.9529e-01, -8.7197e-02,  3.8882e-01, -3.4051e-01, -6.9022e-02,\n",
       "          2.9721e-01,  1.8352e-01,  1.2734e-01,  2.7938e-01, -5.5388e-02,\n",
       "         -1.3446e-01,  2.8717e-03, -2.4914e-01, -1.7240e-01,  5.6754e-02,\n",
       "         -1.1113e-01,  5.4551e-01, -1.4033e-01,  3.1976e-01,  1.9605e-01,\n",
       "          1.4207e-01,  6.4291e-01, -1.1071e-01,  7.6126e-02, -6.4245e-01,\n",
       "          3.5593e-01,  1.6354e-02,  2.9927e-01,  1.5811e-01, -9.0015e-01,\n",
       "          1.2340e-01, -2.1670e-01, -1.3033e-01, -5.9603e-01,  4.4137e-01,\n",
       "          7.5225e-01,  1.0451e-01, -1.1869e-01, -7.4424e-01,  4.2923e-01,\n",
       "         -2.0678e-02,  2.5914e-01,  8.7514e-02, -3.1141e-01,  1.1439e-01,\n",
       "         -1.5802e-01, -1.9444e-01, -3.5095e-01,  6.7247e-01,  5.4727e-01,\n",
       "          1.5959e-02, -2.1647e-02,  1.7429e-01, -1.7409e-01,  7.9685e-02,\n",
       "         -5.9897e-01, -3.2357e-01, -1.4854e-01, -4.2300e-02,  8.7243e-03,\n",
       "         -6.3192e-01, -2.7063e-02, -2.9390e-01,  3.9449e-02, -1.3629e-01,\n",
       "         -4.8443e-01,  2.1076e-01, -5.7421e-01, -3.0318e-01, -3.4293e-01,\n",
       "          3.5555e-01,  9.7892e-02,  5.3140e-01, -7.0200e-01,  4.4414e-01,\n",
       "          3.0163e-01, -4.1291e-01, -3.8952e-01,  1.3163e-02, -2.4731e-01,\n",
       "         -3.4509e-02, -9.0202e-02, -8.1666e+00,  1.4452e-01,  3.0759e-01,\n",
       "          8.6959e-02, -3.7699e-01,  4.3192e-01, -1.0238e+00, -2.0426e+00,\n",
       "          1.0536e-01,  8.0815e-02, -3.6183e-01, -3.7023e-01,  9.1328e-01,\n",
       "         -1.5169e-02, -4.4715e-01, -2.1564e-01, -1.3566e-01, -4.5729e-01,\n",
       "          5.4018e-01, -5.1675e-01,  1.3125e-01,  1.5316e-01,  2.2435e-01,\n",
       "         -9.7898e-02, -8.6780e-01, -5.3929e-02, -1.9564e-01, -2.1166e-01,\n",
       "          2.2493e-01,  2.9048e-01,  4.4283e-01, -1.4625e-01,  2.4096e-01,\n",
       "         -1.4107e-02, -1.3840e-01, -4.1011e-01,  3.1186e-01,  3.9406e-01,\n",
       "         -3.7598e-01,  1.9844e-01,  1.0752e-01,  1.0062e+00,  7.2863e-01,\n",
       "         -3.1163e-02,  2.3556e-01, -1.0101e-01, -9.0243e-02, -4.1497e-01,\n",
       "          2.7261e-01, -6.3646e-02, -3.4019e-01, -1.5133e-01, -4.9654e-01,\n",
       "          2.4267e-01,  1.5938e-01,  2.5838e-01, -4.7945e-01,  3.5367e-01,\n",
       "         -1.7690e-01,  7.3238e-01,  7.8989e-01, -2.6180e-01, -3.5315e-01,\n",
       "         -9.4183e-02,  9.9015e-02,  4.4274e-01, -2.7920e-01,  8.8766e-02,\n",
       "         -2.2762e-01, -9.3903e-02,  4.8509e-01, -3.4539e-01, -1.6387e-01,\n",
       "         -1.4484e-02,  4.1699e-01,  4.1923e-01, -1.4216e-02, -1.4283e-01,\n",
       "          2.5515e-01,  1.5857e-02, -1.2463e-01, -2.5494e-02, -8.8270e-03,\n",
       "          4.5071e-01, -9.5892e-01,  3.0025e-01, -4.0597e-01, -5.9944e-01,\n",
       "         -5.2803e-02, -4.3246e-01, -3.1526e-01, -1.0203e-01, -4.9184e-01,\n",
       "          1.8551e-01,  3.9894e-01,  4.7425e-02, -1.3966e-01,  1.3919e-02,\n",
       "         -6.3617e-01,  2.8754e-01,  3.0226e-02, -1.0082e-01, -5.1055e-01,\n",
       "          2.1826e-01,  4.7981e-01, -1.6199e-03,  4.6361e-01, -3.7803e-01,\n",
       "         -3.7761e-01,  8.5346e-02, -1.1667e-01, -6.5603e-02,  4.4890e-01,\n",
       "         -4.7500e-01,  1.2819e-01, -2.0487e-01, -1.6914e-01,  5.3174e-01,\n",
       "         -1.9094e-01, -3.9277e-01,  1.0777e-01, -1.0366e-01, -2.8411e-01,\n",
       "         -2.4978e-01, -1.4262e-01,  4.2242e-01,  6.1986e-01, -1.7895e-01,\n",
       "          6.1365e-02, -5.1199e-01,  4.8528e-01,  1.9919e-01, -7.9307e-02,\n",
       "          1.9325e-01,  4.6443e-02, -3.2064e-01, -1.0097e-01,  5.9782e-02,\n",
       "          1.3411e-01,  9.3697e-02,  2.0847e-01,  5.5878e-01, -1.1255e-01,\n",
       "          1.4855e-02,  6.6869e-02,  1.8226e-01,  2.4325e-01,  2.8002e-01,\n",
       "          1.1752e-01,  2.5178e-01, -1.4032e-01, -4.4884e-02,  9.6167e-02,\n",
       "         -4.2842e-01, -2.2666e-01, -1.1646e-01, -1.9363e-01,  3.5453e-01,\n",
       "         -8.2521e-02,  3.9498e-01,  2.0901e-01, -1.7084e-02, -1.6326e-01,\n",
       "         -4.2268e-01, -2.7258e-01,  1.2058e-01,  5.3913e-01,  9.8497e-02,\n",
       "         -2.2537e-01,  2.2597e-01, -1.5316e-01,  3.1213e-02, -1.8391e-01,\n",
       "         -2.2793e-02, -1.9526e-01, -4.8039e-01,  4.1023e-02, -3.8369e-02,\n",
       "          4.4164e-01,  1.1186e-01, -8.0709e-02, -4.8706e-01,  1.4107e-01,\n",
       "          1.3534e-01, -4.3471e-01, -3.1242e-02,  3.8436e-03,  1.2232e-01,\n",
       "          2.5886e-01, -1.8224e-01, -3.2830e-01,  1.1284e-01,  1.5567e-01,\n",
       "         -1.8348e-01, -2.1768e+00,  2.4253e-02, -3.3489e-01, -9.5598e-02,\n",
       "          7.3361e-01, -1.3525e-02,  4.4258e-02, -5.0099e-02, -5.5189e-01,\n",
       "         -3.6787e-02, -6.2002e-01,  1.8635e-01, -3.7676e-01, -3.9440e-01,\n",
       "         -3.9858e-01, -5.8887e-01, -6.1379e-02,  2.1626e-01, -2.4001e-01,\n",
       "          3.5864e-02, -2.9282e-01,  2.5462e-01,  3.8679e-01,  1.0632e-01,\n",
       "          1.9115e-01,  4.6083e-01,  1.0053e+00, -1.7265e-01,  9.4624e-02,\n",
       "          3.1210e-01,  3.2784e-01,  2.3402e-01, -5.7963e-02, -4.0943e-01,\n",
       "          3.4745e-01,  1.7191e+00, -1.7328e-01,  1.5293e-01, -4.7443e-02,\n",
       "         -1.2186e-01,  6.8843e-02,  2.7805e-01, -1.4333e-01,  3.3856e-01,\n",
       "         -8.7030e-02, -3.1867e-01,  3.0016e-01,  5.0734e-01, -1.9657e-01,\n",
       "          4.0939e-01, -1.4719e-01, -1.9866e-01,  2.8145e-01,  3.6269e-02,\n",
       "         -5.1875e-02, -1.0519e-01,  6.0337e-02,  1.6265e-01, -2.0610e-01,\n",
       "         -8.9700e-02,  1.7446e-01, -1.4308e-01,  4.1995e-01,  4.3154e-01,\n",
       "         -2.3712e-01, -1.3204e-01,  1.0913e-01, -2.1228e-01,  3.7440e-02,\n",
       "         -3.6065e-01,  2.7520e-01, -2.7747e-01,  5.9120e-02, -4.4395e-01,\n",
       "          1.2053e-01,  7.4692e-02, -2.1207e-01, -5.8461e-02, -6.9639e-01,\n",
       "         -2.0669e-01,  3.6728e-01,  3.5046e-01, -1.2202e-01,  2.0366e-01,\n",
       "         -2.1492e-01,  2.5355e-01, -1.8368e-01, -3.3961e-01, -5.7023e-02,\n",
       "          2.5836e-01,  7.3907e-01,  1.8145e-01,  8.8846e-01,  4.6299e-02,\n",
       "         -6.6664e-02, -6.5222e-01, -4.4008e-02, -4.6648e-01, -1.0750e-01,\n",
       "          6.2471e-01,  1.9138e-01,  1.6123e-01, -3.8818e-01,  7.2050e-01,\n",
       "          2.2369e-01, -3.0080e-01,  1.0512e-01,  1.0797e-01,  4.6637e-01,\n",
       "          1.7488e-01, -4.4796e-01, -2.8426e-01, -1.5629e-01, -2.0339e-01,\n",
       "         -2.1332e-01,  2.3899e-01,  4.0518e-02, -2.4037e-01, -1.6242e-02,\n",
       "         -2.8298e-01,  4.6684e-01,  1.5883e-01,  1.3440e-01,  5.3656e-02,\n",
       "          1.8797e-01,  1.1914e-02, -8.6023e-03, -9.4908e-02,  2.6595e-02,\n",
       "         -2.2561e-01, -2.8006e-02, -3.5304e-01,  2.0680e-01, -8.0153e-03,\n",
       "         -1.9024e-01, -8.4785e-02,  1.8106e-01,  1.7914e-01,  5.8094e-02,\n",
       "          3.6732e-01,  2.0859e-01, -3.9756e-01, -9.9816e-01,  6.6832e-02,\n",
       "         -1.1919e-01,  2.2730e-02, -9.5740e-01, -1.7461e-01,  4.4051e-01,\n",
       "         -1.1065e-01, -1.1439e-02,  7.6019e-02, -3.0607e-01,  3.0240e-02,\n",
       "          1.3229e-01,  4.0096e-01, -5.4285e-02,  3.3838e-02, -1.9108e-01,\n",
       "          1.6378e-01,  4.2834e-02, -1.7066e-01, -5.7157e-01, -1.5679e-01,\n",
       "         -1.5804e-01,  4.3269e-03,  3.1200e-01, -1.5401e-02, -1.7133e-01,\n",
       "         -2.5088e-01,  3.8028e-01, -3.1603e-03, -2.3443e-01, -1.4571e-01,\n",
       "          4.4855e-01, -3.9115e-01,  4.4591e-02,  1.4089e-01, -2.9110e-01,\n",
       "          4.0519e-01,  6.3128e-01, -6.3110e-02, -5.2751e-02, -4.0877e-01,\n",
       "         -2.6288e-01, -1.7865e-01,  1.6064e-01,  9.2726e-03, -2.9552e-02,\n",
       "         -2.3374e-01, -3.5899e-01,  1.3975e-01,  1.1751e-01,  6.4416e-02,\n",
       "          1.2815e-01,  5.9241e-02, -2.2699e-01,  3.8016e-01,  1.2180e-01,\n",
       "          2.8100e-01, -1.4194e-01,  4.2457e-01,  2.8115e-01, -2.6640e-01,\n",
       "          2.2087e-01, -4.5496e-01,  7.5893e-01, -9.1098e-01, -3.8990e-01,\n",
       "         -1.4377e-01, -9.5454e-02,  2.3561e-01, -9.8844e-02, -5.9002e-01,\n",
       "          2.0705e-01, -9.0326e-02,  1.2759e-01, -4.1488e-01,  2.4707e-01,\n",
       "          2.0207e-01,  1.4343e-01, -3.3087e-02, -8.2729e-02,  5.3795e-01,\n",
       "         -9.7299e-02,  7.4076e-02]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f21c1-2fc2-4f5d-8eed-e1b0682ff7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634dfd54-eff5-4694-9c1b-bccba14cd48c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b715d19-abd8-4358-9534-faab08618fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_infra_venv",
   "language": "python",
   "name": "ai_infra_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
